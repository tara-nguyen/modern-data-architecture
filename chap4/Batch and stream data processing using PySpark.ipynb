{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea848f65-1df5-4ca5-a711-eaf6d0082cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from faker import Faker\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    broadcast, spark_partition_id, rand, udf, struct\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    IntegerType, StringType, ArrayType, MapType\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005adc5d-0687-4a8b-864d-f32b8be51c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/18 17:15:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"chap4\")\n",
    "        .config(\"spark.driver.memory\", \"2g\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af6f67-56e5-468e-a6c4-213a9ad51eb8",
   "metadata": {},
   "source": [
    "# Batch Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b86a4-41ed-42ca-b905-2468033dd143",
   "metadata": {},
   "source": [
    "Generate some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55df1a5-f053-4160-b6e3-0e3e185057af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "Faker.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dfa1217-c7a1-45f0-9253-3e2d432c7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (fake.unique.name(), fake.random_int(18, 25), fake.job())\n",
    "    for _ in range(1000)   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e91258-5b49-4b27-9ada-1c79bf1b384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+--------------------+\n",
      "|               name|age|                 job|\n",
      "+-------------------+---+--------------------+\n",
      "|       Norma Fisher| 22|Sales promotion a...|\n",
      "|Dr. Ronald Faulkner| 23|Television produc...|\n",
      "|     Colleen Taylor| 20|      Chief of Staff|\n",
      "|  Danielle Browning| 20|Insurance claims ...|\n",
      "| Benjamin Jefferson| 23|Public house manager|\n",
      "|    Heather Stewart| 21|                 Sub|\n",
      "|         Sean Green| 18|Chief Financial O...|\n",
      "|   Jennifer Summers| 18|  Veterinary surgeon|\n",
      "|    Sean Sanchez MD| 19|Engineer, aeronau...|\n",
      "|       Connie Pratt| 20|Speech and langua...|\n",
      "|       Bobby Flores| 25|Clinical embryolo...|\n",
      "|     Eddie Martinez| 23|Sound technician,...|\n",
      "|       Robert Payne| 22|Producer, televis...|\n",
      "|     Robert Stewart| 21|Horticultural the...|\n",
      "|    Roberto Johnson| 22|     Publishing copy|\n",
      "|   Michael Anderson| 20|     Arboriculturist|\n",
      "|  Stephanie Leblanc| 24|Scientist, water ...|\n",
      "|    Robert Atkinson| 24|        TEFL teacher|\n",
      "| Johnathan Davidson| 23|  Charity fundraiser|\n",
      "|     Brian Matthews| 23|      Energy manager|\n",
      "+-------------------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1 = spark.createDataFrame(data, [\"name\", \"age\", \"job\"])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4368b86e-b4f1-4caf-9767-4e73c8ec0a09",
   "metadata": {},
   "source": [
    "Partition the data by a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7fb043-5a5a-4225-96da-bfd3e5065bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"fake_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb72aeea-6fa6-457f-b5f3-0437b5926780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove directory associated with the table (if it already exists)\n",
    "%rm -rf spark-warehouse/\"$db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2110e1-d72f-4ce8-95dc-98f6b35c5d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.write.saveAsTable(db, partitionBy=\"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392b0f1-0f2f-4fb2-8314-38d0c83e9114",
   "metadata": {},
   "source": [
    "## Data Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0f7d4-3432-4cdf-807d-d0f16aa9fa53",
   "metadata": {},
   "source": [
    "Data skew is when data is unevenly distributed across partitions. This slows down performance and needs handling. Most of the time, Spark's Adaptive Query Engine (AQE) is efficient in optimizing the data distribution. However, sometimes we need to manually fix the data skew problem. Here are some ways to do it:\n",
    "- Configuring the number of partitions to use when shuffling data for joins or aggregations (i.e., the `spark.sql.shuffle.partitions` option). See the [Working With Partitions](http://localhost:8888/notebooks/chap3/Apache%20Spark%20deep%20dive.ipynb#Working-With-Partitions) section in the Chapter 3 notebook for more information.\n",
    "- Broadcast join: Send the smaller dataset across all nodes and then join each node's portion of the larger dataset. This is suitable for small-to-medium-sized DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9804d95e-5fad-4e9b-a50e-964586b4a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = pd.DataFrame({\n",
    "    \"name\": fake.random_sample([tup[0] for tup in data], 5),\n",
    "    \"catchPhrase\": [fake.unique.catch_phrase() for _ in range(5)]\n",
    "})\n",
    "df2 = spark.createDataFrame(pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14859c3b-c2de-4753-a0aa-8c2e893fcf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+--------------------+--------------------+\n",
      "|            name|age|                 job|         catchPhrase|\n",
      "+----------------+---+--------------------+--------------------+\n",
      "|     Daniel Cruz| 19|Nurse, mental health|Public-key mobile...|\n",
      "|Reginald Garrett| 24|     Arboriculturist|Visionary systema...|\n",
      "|  Victoria Reese| 25|Health and safety...|Multi-layered hyb...|\n",
      "| Brent Willis MD| 23|           Ecologist|Fundamental inter...|\n",
      "| Dustin Mcdowell| 22|Senior tax profes...|Multi-lateral zer...|\n",
      "+----------------+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df1.join(broadcast(df2), \"name\")\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b07d8d-1cd4-429b-affc-1ac0e259bfb3",
   "metadata": {},
   "source": [
    "- Salting (idea from cryptography): Add a random or unique identifier to each record. This is useful if we are unsure what column we want to repartition by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8800610-239c-4acb-93fc-fc0ebde99047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+--------------------+----+\n",
      "|               name|age|                 job|salt|\n",
      "+-------------------+---+--------------------+----+\n",
      "|       Norma Fisher| 22|Sales promotion a...|   7|\n",
      "|Dr. Ronald Faulkner| 23|Television produc...|   5|\n",
      "|     Colleen Taylor| 20|      Chief of Staff|   0|\n",
      "|  Danielle Browning| 20|Insurance claims ...|   3|\n",
      "| Benjamin Jefferson| 23|Public house manager|   7|\n",
      "|    Heather Stewart| 21|                 Sub|   2|\n",
      "|         Sean Green| 18|Chief Financial O...|   2|\n",
      "|   Jennifer Summers| 18|  Veterinary surgeon|   5|\n",
      "|    Sean Sanchez MD| 19|Engineer, aeronau...|   7|\n",
      "|       Connie Pratt| 20|Speech and langua...|   0|\n",
      "|       Bobby Flores| 25|Clinical embryolo...|   2|\n",
      "|     Eddie Martinez| 23|Sound technician,...|   6|\n",
      "|       Robert Payne| 22|Producer, televis...|   4|\n",
      "|     Robert Stewart| 21|Horticultural the...|   5|\n",
      "|    Roberto Johnson| 22|     Publishing copy|   3|\n",
      "|   Michael Anderson| 20|     Arboriculturist|   2|\n",
      "|  Stephanie Leblanc| 24|Scientist, water ...|   0|\n",
      "|    Robert Atkinson| 24|        TEFL teacher|   4|\n",
      "| Johnathan Davidson| 23|  Charity fundraiser|   6|\n",
      "|     Brian Matthews| 23|      Energy manager|   2|\n",
      "+-------------------+---+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.withColumn(\"salt\", (rand(0) * 10).cast(\"int\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558f7a4-89ab-4590-b4b4-4c90c082c420",
   "metadata": {},
   "source": [
    "# Spark Schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac28d506-7a20-4269-b386-06d7d35e253a",
   "metadata": {},
   "source": [
    "To define a `StructField`, set three components: name, data type, and nullibility (`True` by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4145ebaf-f613-4a1a-9273-3695d1db392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\n",
    "        \"user\",\n",
    "        StructType([\n",
    "            StructField(\"name\", StringType(), False),\n",
    "            StructField(\"age\", IntegerType())\n",
    "        ])\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8a81621-f086-489c-b84b-08ef81bb53e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField('id', IntegerType(), False),\n",
       " StructField('user', StructType([StructField('name', StringType(), False), StructField('age', IntegerType(), True)]), True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema1.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6669742a-3ba5-478a-bca4-73e0b1971bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'user']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema1.fieldNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e32eb-78e5-4ef1-9cb4-3ae5f83160bf",
   "metadata": {},
   "source": [
    "Schemas are objects so we can compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e199e9cb-314d-4698-bc00-824970f89f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema2 = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\n",
    "        \"user\",\n",
    "        StructType([\n",
    "            StructField(\"name\", StringType(), False),\n",
    "            StructField(\"age\", IntegerType())\n",
    "        ])\n",
    "    )\n",
    "])\n",
    "schema1 == schema2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5891b-3b42-4993-8586-a5af42734c86",
   "metadata": {},
   "source": [
    "Make sure that fields are in the correct order across the two schemas being compared, since column order is not guaranteed in Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63a1491c-2b56-41e5-bd66-3def82845cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema3 = StructType([\n",
    "    StructField(\n",
    "        \"user\",\n",
    "        StructType([\n",
    "            StructField(\"name\", StringType(), False),\n",
    "            StructField(\"age\", IntegerType())\n",
    "        ])\n",
    "    ),\n",
    "    StructField(\"id\", IntegerType(), False)\n",
    "])\n",
    "schema1 == schema3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e09979f-3601-4eb0-a043-dd9e7bb1503f",
   "metadata": {},
   "source": [
    "`ArrayType`: Specify the data type of elements in the array (and, optionally, the nullibility of the array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a02055a6-9f11-4d6e-a90c-06aa2aac27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_struct = StructField(\"skills\", ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec312d1-cd0e-48f0-bab7-3b8dfbe08346",
   "metadata": {},
   "source": [
    "`MapType`: Specify the data types of the key and of the values in the map (and, optionally, the nullibility of the map)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6b0a3aa-d10e-40ae-b2f2-7f6f93a5a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_type = MapType(StringType(), StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3375ff-aab1-4b78-bd0f-9e11c3d563fc",
   "metadata": {},
   "source": [
    "Add new fields to a schema: Provide either a `StructField` object or the name and data type of the new field. The data type can be either a `DataType` object or a string representing the object. Optionally, specify the nullibility of the new field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca8ea728-839a-44be-bc8c-424e3ca2b957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'user', 'skills', 'info_string', 'score']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema1 = (\n",
    "    schema1.add(array_struct)\n",
    "        .add(\"info_string\", map_type)\n",
    "        .add(\"score\", \"float\", False)\n",
    ")\n",
    "schema1.fieldNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16aa46e-2f5c-4216-829c-2c4a03a083c4",
   "metadata": {},
   "source": [
    "# User-defined Functions (UDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c85291-cd83-41d8-8ddd-b16ce7e5e431",
   "metadata": {},
   "source": [
    "UDFs: slower than native Python functions and methods because Spark cannot optimize UDFs. Only use UDFs when it's impossible to do something using the normal Spark API and the speed hit is not a concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90ad858a-55e8-46aa-b9dd-ad4825a1c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_one_udf = udf(lambda x: x + 1, \"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1babe06-216a-4130-ab78-abed1252de85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "|age|age_plus_one|\n",
      "+---+------------+\n",
      "| 19|          20|\n",
      "| 24|          25|\n",
      "| 25|          26|\n",
      "| 23|          24|\n",
      "| 22|          23|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(\n",
    "    \"age\", add_one_udf(\"age\").alias(\"age_plus_one\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7b054-3c65-47f0-bf3d-dcda1b5f3429",
   "metadata": {},
   "source": [
    "Define a UDF using a decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c85b3d9f-0965-4a0a-9ed8-b73cb6c6c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(\"string\")\n",
    "def concat(s):\n",
    "    return \": \".join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3c77c1e-a2dd-4327-9d2a-47d441f6cc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+\n",
      "|name_and_job                                          |\n",
      "+------------------------------------------------------+\n",
      "|Daniel Cruz: Nurse, mental health                     |\n",
      "|Reginald Garrett: Arboriculturist                     |\n",
      "|Victoria Reese: Health and safety adviser             |\n",
      "|Brent Willis MD: Ecologist                            |\n",
      "|Dustin Mcdowell: Senior tax professional/tax inspector|\n",
      "+------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(\n",
    "    concat(struct(\"name\", \"job\")).alias(\"name_and_job\")\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d8849-4ef4-4edc-98c2-acfa5eea798a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Further reading**:\n",
    "\n",
    "- [Deep Dive into Handling Apache Spark Data Skew](https://chengzhizhao.com/deep-dive-into-handling-apache-spark-data-skew/) (Zhao, 2022)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
